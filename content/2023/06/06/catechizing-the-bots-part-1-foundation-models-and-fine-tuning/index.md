---
title: "å¯¹æœºå™¨äººè¿›è¡Œæ•™ç†é—®ç­”ï¼Œç¬¬ 1 éƒ¨åˆ†ï¼šåŸºç¡€æ¨¡å‹å’Œå¾®è°ƒ"
date: 2023-06-06T07:01:56+08:00
updated: 2023-06-06T07:01:56+08:00
taxonomies:
  tags: []
extra:
  source: https://www.jonstokes.com/p/catechizing-the-bots-part-1-foundation
  hostname: www.jonstokes.com
  author: Jon Stokes
  original_title: "Catechizing the Bots, Part 1: Foundation Models and Fine-Tuning"
  original_lang: zh
---

[![](https3A2F2Fsubstack-post-media.s3.amazonaws.com2Fpublic2Fimages2F2fb2c563-a5de-4f2d-98ff-2250c42f9048_1312x928.jpeg)](https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2fb2c563-a5de-4f2d-98ff-2250c42f9048_1312x928.jpeg)

_**The story so far:**Â Weâ€™ve all read the endless commentary on ChatGPTâ€™s political biases, and in fact, Iâ€™ve written a few tweets on this topic, myself. But where do these biases come from?  

How is this large language model, trained on trillions of words of text, given a particular worldview, a set of values, political opinions, or, if weâ€™re being generous, â€œguardrailsâ€?  

ç»™å®šä¸€ä¸ªç‰¹å®šçš„ä¸–ç•Œè§‚ã€ä¸€ç»„ä»·å€¼è§‚ã€æ”¿æ²»è§‚ç‚¹ï¼Œæˆ–è€…ï¼Œå¦‚æœæˆ‘ä»¬æ…·æ…¨çš„è¯ï¼Œâ€œæŠ¤æ â€ï¼Œè¿™ä¸ªåœ¨æ•°ä¸‡äº¿æ–‡æœ¬å•è¯ä¸Šè®­ç»ƒçš„å¤§å‹è¯­è¨€æ¨¡å‹å¦‚ä½•ï¼Ÿ  

åˆ°ç›®å‰ä¸ºæ­¢çš„æ•…äº‹ï¼šæˆ‘ä»¬éƒ½è¯»è¿‡å…³äº ChatGPT æ”¿æ²»åè§çš„æ²¡å®Œæ²¡äº†çš„è¯„è®ºï¼Œäº‹å®ä¸Šï¼Œæˆ‘è‡ªå·±ä¹Ÿå†™äº†ä¸€äº›å…³äºè¿™ä¸ªè¯é¢˜çš„æ¨æ–‡ã€‚ä½†è¿™äº›åè§ä»ä½•è€Œæ¥ï¼Ÿ_

_This business of taking pre-trained foundation models and infusing them with values, morals, and politics, is the undoubtedly most contested and politically sensitive part of the whole AI endeavor.  

è¿™ç§é‡‡ç”¨é¢„å…ˆè®­ç»ƒçš„åŸºç¡€æ¨¡å‹å¹¶ä¸ºå®ƒä»¬æ³¨å…¥ä»·å€¼è§‚ã€é“å¾·å’Œæ”¿æ²»çš„ä¸šåŠ¡ï¼Œæ— ç–‘æ˜¯æ•´ä¸ª AI åŠªåŠ›ä¸­æœ€å…·äº‰è®®å’Œæ”¿æ²»æ•æ„Ÿæ€§çš„éƒ¨åˆ†ã€‚  

This is true no matter [which â€œAI safetyâ€ camp](https://www.jonstokes.com/p/ai-safety-a-technical-and-ethnographic) you fall into.  

Whether youâ€™re worried about existential risks to humanity, representational harms and microaggressions, or ML-powered industrial control systems gone wild, it all begins and ends with the processes Iâ€™ll describe in this article and the next.  

æ— è®ºæ‚¨æ˜¯æ‹…å¿ƒäººç±»å­˜åœ¨çš„é£é™©ã€ä»£è¡¨æ€§ä¼¤å®³å’Œå¾®æ”»å‡»ï¼Œè¿˜æ˜¯ ML é©±åŠ¨çš„å·¥ä¸šæ§åˆ¶ç³»ç»Ÿå˜å¾—ç–¯ç‹‚ï¼Œè¿™ä¸€åˆ‡éƒ½ä»¥æˆ‘å°†åœ¨æœ¬æ–‡å’Œä¸‹ä¸€ç¯‡æ–‡ç« ä¸­æè¿°çš„è¿‡ç¨‹å¼€å§‹å’Œç»“æŸã€‚  

æ— è®ºæ‚¨å±äºå“ªä¸ªâ€œAI å®‰å…¨â€é˜µè¥ï¼Œéƒ½æ˜¯å¦‚æ­¤ã€‚_

_This is the part of the whole AI picture where the models are humanized. Or, to use the [language](https://claremontreviewofbooks.com/podcast/the-close-read-james-poulos-on-digital-religion/) of my_

_colleague_

_, we could say itâ€™s where the models are catechized â€” itâ€™s where theyâ€™re instructed morally._  

è¿™æ˜¯æ•´ä¸ª AI å›¾ç‰‡ä¸­æ¨¡å‹è¢«äººæ€§åŒ–çš„éƒ¨åˆ†ã€‚æˆ–è€…ï¼Œç”¨æˆ‘çš„ RETURN åŒäº‹ James Poulos çš„è¯æ¥è¯´ï¼Œæˆ‘ä»¬å¯ä»¥è¯´è¿™æ˜¯å¯¹æ¨¡å‹è¿›è¡Œæ•™ç†é—®ç­”çš„åœ°æ–¹â€”â€”è¿™æ˜¯å¯¹ä»–ä»¬è¿›è¡Œé“å¾·æ•™è‚²çš„åœ°æ–¹ã€‚

_How does this catechesis work? What texts form the basis for it? Who are the people writing and/or collecting these texts? Whose values do these texts express?  

è¿™ä¸ªè¦ç†è®²æˆæ˜¯å¦‚ä½•è¿›è¡Œçš„ï¼Ÿå“ªäº›æ–‡æœ¬æ„æˆäº†å®ƒçš„åŸºç¡€ï¼Ÿè°åœ¨æ’°å†™å’Œ/æˆ–æ”¶é›†è¿™äº›æ–‡æœ¬ï¼Ÿè¿™äº›æ–‡æœ¬è¡¨è¾¾äº†è°çš„ä»·å€¼è§‚ï¼Ÿ_

_These are all important questions, and I plan to chip away at them over the course of this series.  

è¿™äº›éƒ½æ˜¯é‡è¦çš„é—®é¢˜ï¼Œæˆ‘è®¡åˆ’åœ¨æœ¬ç³»åˆ—çš„è¯¾ç¨‹ä¸­é€æ­¥è§£å†³è¿™äº›é—®é¢˜ã€‚_

The large language models weâ€™re using now, especially the models from OpenAI, Google, and Anthropic, all have something important in common: theyâ€™ve gone through a set of post-trainingÂ **fine-tuning phases**Â that make them easier for humans to use but at a cost.  

æˆ‘ä»¬ç°åœ¨ä½¿ç”¨çš„å¤§å‹è¯­è¨€æ¨¡å‹ï¼Œå°¤å…¶æ˜¯æ¥è‡ª OpenAIã€Google å’Œ Anthropic çš„æ¨¡å‹ï¼Œéƒ½æœ‰ä¸€ä¸ªé‡è¦çš„å…±åŒç‚¹ï¼šå®ƒä»¬éƒ½ç»å†äº†ä¸€ç³»åˆ—è®­ç»ƒåçš„å¾®è°ƒé˜¶æ®µï¼Œä½¿äººç±»æ›´å®¹æ˜“ç†è§£å®ƒä»¬ä½¿ç”¨ï¼Œä½†è¦ä»˜å‡ºä»£ä»·ã€‚

In this series, Iâ€™ll talk about what those phases are and what their downsides are. When Iâ€™m done, I hope a few points will be clear:  

åœ¨æœ¬ç³»åˆ—ä¸­ï¼Œæˆ‘å°†è®¨è®ºè¿™äº›é˜¶æ®µæ˜¯ä»€ä¹ˆä»¥åŠå®ƒä»¬çš„ç¼ºç‚¹æ˜¯ä»€ä¹ˆã€‚å½“æˆ‘å®Œæˆåï¼Œæˆ‘å¸Œæœ›æœ‰å‡ ç‚¹ä¼šå¾ˆæ¸…æ¥šï¼š

-   Humans play a critical role in finishing off LLMs and making them work the way we want them to work.  
    
    äººç±»åœ¨å®Œæˆ LLM å¹¶ä½¿ä»–ä»¬æŒ‰ç…§æˆ‘ä»¬å¸Œæœ›çš„æ–¹å¼å·¥ä½œæ–¹é¢å‘æŒ¥ç€å…³é”®ä½œç”¨ã€‚
    
-   Following on the above, which humans are tasked with shaping the models matters a great deal â€” their values, education, intelligence, politics, etc.  
    
    æ ¹æ®ä¸Šè¿°å†…å®¹ï¼Œå“ªäº›äººè´Ÿè´£å¡‘é€ æ¨¡å‹éå¸¸é‡è¦â€”â€”ä»–ä»¬çš„ä»·å€¼è§‚ã€æ•™è‚²ã€æ™ºåŠ›ã€æ”¿æ²»ç­‰ã€‚  
    
    All of this affects the output of the models they work on, and by the time youâ€™re finished with this article that relationship should be pretty apparent and straightforward.  
    
    æ‰€æœ‰è¿™äº›éƒ½ä¼šå½±å“ä»–ä»¬å·¥ä½œçš„æ¨¡å‹çš„è¾“å‡ºï¼Œå½“æ‚¨è¯»å®Œæœ¬æ–‡æ—¶ï¼Œè¿™ç§å…³ç³»åº”è¯¥éå¸¸æ˜æ˜¾å’Œç›´æ¥ã€‚
    
-   The main way selected groups of humans shape LLMs is by selecting, rating, and even generating the texts used for fine-tuning and reinforcement learning.  
    
    é€‰å®šçš„äººç±»ç¾¤ä½“å¡‘é€  LLM çš„ä¸»è¦æ–¹å¼æ˜¯é€‰æ‹©ã€è¯„çº§ï¼Œç”šè‡³ç”Ÿæˆç”¨äºå¾®è°ƒå’Œå¼ºåŒ–å­¦ä¹ çš„æ–‡æœ¬ã€‚  
    
    This is a form of textual scholarship and should be treated as such.  
    
    è¿™æ˜¯ä¸€ç§æ–‡æœ¬å­¦æœ¯å½¢å¼ï¼Œåº”è¯¥è¿™æ ·å¯¹å¾…ã€‚
    
-   In the near term, many of us will get the chance to fine-tune models for widespread use. We should take that chance because this work matters.  
    
    åœ¨çŸ­æœŸå†…ï¼Œæˆ‘ä»¬ä¸­çš„è®¸å¤šäººå°†æœ‰æœºä¼šå¾®è°ƒæ¨¡å‹ä»¥ä¾›å¹¿æ³›ä½¿ç”¨ã€‚æˆ‘ä»¬åº”è¯¥æŠ“ä½è¿™ä¸ªæœºä¼šï¼Œå› ä¸ºè¿™é¡¹å·¥ä½œå¾ˆé‡è¦ã€‚
    
-   In the long term, we may not actually need fine-tuning.  
    
    ä»é•¿è¿œæ¥çœ‹ï¼Œæˆ‘ä»¬å®é™…ä¸Šå¯èƒ½ä¸éœ€è¦å¾®è°ƒã€‚  
    
    Itâ€™s quite possible that weâ€™ll be able to use models that havenâ€™t been fine-tuned just as capably as we use models that have.  
    
    å¾ˆæœ‰å¯èƒ½æˆ‘ä»¬å¯ä»¥ä½¿ç”¨æœªç»å¾®è°ƒçš„æ¨¡å‹ï¼Œå°±åƒæˆ‘ä»¬ä½¿ç”¨ç»è¿‡å¾®è°ƒçš„æ¨¡å‹ä¸€æ ·æœ‰æ•ˆã€‚
    
-   Even if we donâ€™t end up needing to do fine-tuning or reinforcement learning, weâ€™re still going to be curating and generating collections of texts for the sole purpose of shaping and steering LLMs morally, politically, and socially.  
    
    å³ä½¿æˆ‘ä»¬æœ€ç»ˆä¸éœ€è¦è¿›è¡Œå¾®è°ƒæˆ–å¼ºåŒ–å­¦ä¹ ï¼Œæˆ‘ä»¬ä»å°†ç­–åˆ’å’Œç”Ÿæˆæ–‡æœ¬é›†åˆï¼Œå…¶å”¯ä¸€ç›®çš„æ˜¯åœ¨é“å¾·ã€æ”¿æ²»å’Œç¤¾ä¼šæ–¹é¢å¡‘é€ å’ŒæŒ‡å¯¼æ³•å­¦ç¡•å£«ã€‚
    

Most readers whoâ€™ve at least skimmed some of my earlier posts will be familiar with the basic concept ofÂ **training a model**.  

(This is actually now called â€œpretraining,â€ but Iâ€™m going to stick with just â€œtraining.â€) This training phase, where a modelâ€™s weights are progressively adjusted in passes by exposing it to hundreds of billions of examples of language, is only the first of a series of three phases most LLMs go through right now:  

ï¼ˆè¿™å®é™…ä¸Šç°åœ¨ç§°ä¸ºâ€œé¢„è®­ç»ƒâ€ï¼Œä½†æˆ‘å°†åšæŒåªä½¿ç”¨â€œè®­ç»ƒâ€ã€‚ï¼‰åœ¨è¿™ä¸ªè®­ç»ƒé˜¶æ®µï¼Œæ¨¡å‹çš„æƒé‡é€šè¿‡å°†å…¶æš´éœ²äºæ•°åƒäº¿ä¸ªè¯­è¨€ç¤ºä¾‹æ¥é€æ­¥è°ƒæ•´ï¼Œæ˜¯å¤§å¤šæ•°æ³•å­¦ç¡•å£«ç›®å‰æ­£åœ¨ç»å†çš„ä¸€ç³»åˆ—ä¸‰ä¸ªé˜¶æ®µä¸­çš„ç¬¬ä¸€ä¸ªé˜¶æ®µï¼š  

å¤§å¤šæ•°è‡³å°‘æµè§ˆè¿‡æˆ‘ä¹‹å‰çš„ä¸€äº›å¸–å­çš„è¯»è€…éƒ½ä¼šç†Ÿæ‚‰è®­ç»ƒæ¨¡å‹çš„åŸºæœ¬æ¦‚å¿µã€‚

[![](https3A2F2Fsubstack-post-media.s3.amazonaws.com2Fpublic2Fimages2Faf6d34d5-e8ac-4e1a-81ad-e0255621469c_2152x982.png)](https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Faf6d34d5-e8ac-4e1a-81ad-e0255621469c_2152x982.png)

While the training phase gives the model an understanding of the structure of language and a set of facts about the world, the latter two phases are aimed at getting the model into a shape that we humans can more easily use.Â   

è™½ç„¶è®­ç»ƒé˜¶æ®µè®©æ¨¡å‹äº†è§£è¯­è¨€çš„ç»“æ„å’Œä¸€ç»„å…³äºä¸–ç•Œçš„äº‹å®ï¼Œä½†åä¸¤ä¸ªé˜¶æ®µçš„ç›®çš„æ˜¯è®©æ¨¡å‹æˆä¸ºæˆ‘ä»¬äººç±»æ›´å®¹æ˜“ä½¿ç”¨çš„å½¢çŠ¶ã€‚

When a large language model (LLM) has completed its training, itâ€™s not actually very usable, at least if youâ€™re hoping to feed it an uncomplicated text prompt and get something helpful back.  

å½“ä¸€ä¸ªå¤§å‹è¯­è¨€æ¨¡å‹ (LLM) å®Œæˆè®­ç»ƒåï¼Œå®ƒå®é™…ä¸Šå¹¶ä¸æ˜¯å¾ˆæœ‰ç”¨ï¼Œè‡³å°‘å¦‚æœä½ å¸Œæœ›å‘å®ƒæä¾›ä¸€ä¸ªç®€å•çš„æ–‡æœ¬æç¤ºå¹¶å¾—åˆ°ä¸€äº›æœ‰ç”¨çš„åé¦ˆçš„è¯ã€‚  

These so-calledÂ **foundation models**Â have been trained to predict the next word in a sequence, and as a result, they can produce coherent-sounding sentences that are related to the prompt but that donâ€™t feel like aÂ _response_Â to your input.  

è¿™äº›æ‰€è°“çš„åŸºç¡€æ¨¡å‹ç»è¿‡è®­ç»ƒå¯ä»¥é¢„æµ‹åºåˆ—ä¸­çš„ä¸‹ä¸€ä¸ªå•è¯ï¼Œå› æ­¤ï¼Œå®ƒä»¬å¯ä»¥ç”Ÿæˆä¸æç¤ºç›¸å…³ä½†å¬èµ·æ¥ä¸åƒæ˜¯å¯¹æ‚¨è¾“å…¥çš„å›åº”çš„è¿è´¯å¥å­ã€‚

ğŸ—£ï¸ To anthropomorphize a bit, a foundation model hasÂ **no social skills**.  

When you ask it a question, it extemporizes a brand new text document thatâ€™s connected to the prompt but that lacks any qualities that might make you, the human questioner, feel like itâ€™s a competent dialogue partner giving you a direct response.  

å½“ä½ é—®å®ƒä¸€ä¸ªé—®é¢˜æ—¶ï¼Œå®ƒä¼šå³å…´ç”Ÿæˆä¸€ä¸ªä¸æç¤ºç›¸å…³çš„å…¨æ–°æ–‡æœ¬æ–‡æ¡£ï¼Œä½†å®ƒç¼ºä¹ä»»ä½•å¯èƒ½è®©ä½ ï¼Œäººç±»æé—®è€…ï¼Œæ„Ÿè§‰å®ƒæ˜¯ä¸€ä¸ªèƒ½ç»™ä½ ç›´æ¥å›åº”çš„å¯¹è¯ä¼™ä¼´çš„å“è´¨ã€‚  

ğŸ—£ï¸ æ‹ŸäººåŒ–ä¸€ç‚¹ï¼ŒåŸºç¡€æ¨¡ç‰¹æ²¡æœ‰ç¤¾äº¤èƒ½åŠ›ã€‚

**Example:**Â Imagine youâ€™re a tourist in some foreign city, and you come across a scrap of paper in the street with some lines of text on it.  

Most of the text is damaged and unreadable, but amidst all the mess you can make out the words â€œHow do I change a tire?â€.  

å¤§éƒ¨åˆ†æ–‡å­—å·²æŸåä¸”æ— æ³•è¾¨è®¤ï¼Œä½†åœ¨ä¸€ç‰‡æ··ä¹±ä¸­ï¼Œæ‚¨å¯ä»¥è¾¨è®¤å‡ºâ€œæˆ‘å¦‚ä½•æ›´æ¢è½®èƒï¼Ÿâ€è¿™å‡ ä¸ªå­—ã€‚  

In order to interpret that scrap of text â€” as part of a dialogue between two people, a line from an advertisement, a mysterious message left just for you, etc.  

ä¸ºäº†è§£é‡Šé‚£æ®µæ–‡å­—â€”â€”ä½œä¸ºä¸¤ä¸ªäººå¯¹è¯çš„ä¸€éƒ¨åˆ†ï¼Œå¹¿å‘Šä¸­çš„ä¸€å¥è¯ï¼Œåªä¸ºä½ ç•™ä¸‹çš„ç¥ç§˜ä¿¡æ¯ï¼Œç­‰ç­‰ã€‚  

â€” youâ€™ll look for other clues on the page.  

â€”â€”ä½ ä¼šåœ¨é¡µé¢ä¸Šå¯»æ‰¾å…¶ä»–çº¿ç´¢ã€‚  

You may look for some graphic design elements, or at the way the missing text is laid out on the page, or you may consider the part of town you found the note in.  

æ‚¨å¯èƒ½ä¼šå¯»æ‰¾ä¸€äº›å›¾å½¢è®¾è®¡å…ƒç´ ï¼Œæˆ–è€…é¡µé¢ä¸Šç¼ºå¤±æ–‡æœ¬çš„å¸ƒå±€æ–¹å¼ï¼Œæˆ–è€…æ‚¨å¯èƒ½ä¼šè€ƒè™‘æ‰¾åˆ°è¯¥æ³¨é‡Šçš„åŸé•‡éƒ¨åˆ†ã€‚  

ç¤ºä¾‹ï¼šå‡è®¾æ‚¨æ˜¯æŸä¸ªå¤–å›½åŸå¸‚çš„æ¸¸å®¢ï¼Œæ‚¨åœ¨è¡—ä¸Šçœ‹åˆ°ä¸€å¼ çº¸ç‰‡ï¼Œä¸Šé¢æœ‰å‡ è¡Œæ–‡å­—ã€‚

When you put that same text into GPT-4â€™s foundation model, it enters the model totally stripped of any such interpretive cues and clues.  

å½“æ‚¨å°†ç›¸åŒçš„æ–‡æœ¬æ”¾å…¥ GPT-4 çš„åŸºç¡€æ¨¡å‹æ—¶ï¼Œå®ƒè¿›å…¥æ¨¡å‹æ—¶å®Œå…¨æ²¡æœ‰ä»»ä½•æ­¤ç±»è§£é‡Šæ€§çº¿ç´¢å’Œçº¿ç´¢ã€‚  

All the model has to go on is this disembodied scrap of text that comes with no other context. Wat mean?  

æ‰€æœ‰æ¨¡å‹å¿…é¡»ç»§ç»­ä¸‹å»çš„æ˜¯æ²¡æœ‰å…¶ä»–ä¸Šä¸‹æ–‡çš„æ— å½¢æ–‡æœ¬ç‰‡æ®µã€‚ä»€ä¹ˆæ„æ€ï¼Ÿ

â‰ï¸ So if I ask GPT-4â€™s foundation model: â€œHow do I change a tire?â€ I might get any of the following bits of text as output:  

â‰ï¸ æ‰€ä»¥å¦‚æœæˆ‘é—® GPT-4 çš„åŸºç¡€æ¨¡å‹ï¼šâ€œæˆ‘è¯¥å¦‚ä½•æ›´æ¢è½®èƒï¼Ÿâ€æˆ‘å¯èƒ½ä¼šå¾—åˆ°ä»¥ä¸‹ä»»ä½•ä¸€æ®µæ–‡æœ¬ä½œä¸ºè¾“å‡ºï¼š

-   â€œIâ€™m sorry for calling you this late with this question, but Iâ€™m stuck on the side of a busy road and I need help.â€  
    
    â€œå¾ˆæŠ±æ­‰è¿™ä¹ˆæ™šæ‰“ç”µè¯ç»™ä½ é—®è¿™ä¸ªé—®é¢˜ï¼Œä½†æˆ‘è¢«å›°åœ¨ç¹å¿™çš„è·¯è¾¹ï¼Œæˆ‘éœ€è¦å¸®åŠ©ã€‚â€
    
-   â€œTake your time answering. No pressure ğŸ˜†.â€  
    
    â€œæ…¢æ…¢æ¥å›ç­”ã€‚æ²¡æœ‰å‹åŠ›ğŸ˜†ã€‚â€
    
-   â€œJames stared at the flat and repeated the question to himself, regretting that he had never payed attention the few times his father had changed flat tires on family road trips.â€  
    
    â€œè©¹å§†æ–¯ç›¯ç€è½®èƒï¼Œå¯¹è‡ªå·±é‡å¤äº†è¿™ä¸ªé—®é¢˜ï¼Œåæ‚”è‡ªå·±æ²¡æœ‰æ³¨æ„ä»–çˆ¶äº²åœ¨å®¶åº­å…¬è·¯æ—…è¡Œä¸­å‡ æ¬¡æ›´æ¢æ¼æ°”è½®èƒã€‚â€
    
-   â€œBegin by ensuring that the car is safely off the shoulder of the road and away from trafficâ€¦â€  
    
    â€œé¦–å…ˆç¡®ä¿æ±½è½¦å®‰å…¨åœ°ç¦»å¼€è·¯è‚©å¹¶è¿œç¦»äº¤é€šâ€¦â€¦â€
    

In other words, when a prompt contains a direct question with no context clues that can guide interpretation, thereâ€™s actuallyÂ _no reason at all_Â for a foundation model to assume the most appropriate output is an answer to the promptâ€™s question. These foundation models areÂ **trained to complete sentences**Â that are missing words â€” to â€œpredict the next token.â€ Theyâ€™re not (yet) trained to actually interpret prompts based on any inferences about what a â€œuserâ€ may have wanted.  

æ¢å¥è¯è¯´ï¼Œå½“æç¤ºåŒ…å«ä¸€ä¸ªæ²¡æœ‰ä¸Šä¸‹æ–‡çº¿ç´¢å¯ä»¥æŒ‡å¯¼è§£é‡Šçš„ç›´æ¥é—®é¢˜æ—¶ï¼Œå®é™…ä¸Šæ ¹æœ¬æ²¡æœ‰ç†ç”±è®©åŸºç¡€æ¨¡å‹å‡è®¾æœ€åˆé€‚çš„è¾“å‡ºæ˜¯æç¤ºé—®é¢˜çš„ç­”æ¡ˆã€‚è¿™äº›åŸºç¡€æ¨¡å‹ç»è¿‡è®­ç»ƒå¯ä»¥å®Œæˆç¼ºå°‘å•è¯çš„å¥å­â€”â€”â€œé¢„æµ‹ä¸‹ä¸€ä¸ªæ ‡è®°â€ã€‚ä»–ä»¬ï¼ˆè¿˜ï¼‰æ²¡æœ‰æ¥å—è¿‡æ ¹æ®â€œç”¨æˆ·â€å¯èƒ½æƒ³è¦ä»€ä¹ˆçš„ä»»ä½•æ¨æ–­æ¥å®é™…è§£é‡Šæç¤ºçš„è®­ç»ƒã€‚

ğŸ¤·â™‚ï¸ The foundation model either needs much more information added to the prompt alongside the question if itâ€™s going to know how to respond, or it needs to be further trained to assume that the most appropriate output for a direct question is a direct answer.Â   

ğŸ¤·â™‚ï¸ åŸºç¡€æ¨¡å‹å¦‚æœè¦çŸ¥é“å¦‚ä½•å›ç­”ï¼Œè¦ä¹ˆéœ€è¦åœ¨é—®é¢˜æ—è¾¹æ·»åŠ æ›´å¤šä¿¡æ¯ï¼Œè¦ä¹ˆéœ€è¦è¿›ä¸€æ­¥è®­ç»ƒä»¥å‡è®¾æœ€é€‚åˆç›´æ¥é—®é¢˜çš„è¾“å‡ºæ˜¯ç›´æ¥ç­”æ¡ˆã€‚

ğŸ‘‰ **To summarize**, a foundation model has the following qualities:  

ğŸ‘‰æ€»è€Œè¨€ä¹‹ï¼ŒåŸºç¡€æ¨¡å‹å…·æœ‰ä»¥ä¸‹å“è´¨ï¼š

-   Itâ€™s aÂ **model weights file**Â that can be copied, distributed, and used by anyone who has the right combination of hardware and supporting code.  
    
    å®ƒæ˜¯ä¸€ä¸ªæ¨¡å‹æƒé‡æ–‡ä»¶ï¼Œä»»ä½•æ‹¥æœ‰æ­£ç¡®çš„ç¡¬ä»¶å’Œæ”¯æŒä»£ç ç»„åˆçš„äººéƒ½å¯ä»¥å¤åˆ¶ã€åˆ†å‘å’Œä½¿ç”¨ã€‚
    
-   Itâ€™s aÂ **raw industrial product**, the unfinished output of a capital-intensive industrial process.  
    
    å®ƒæ˜¯ä¸€ç§åŸå§‹å·¥ä¸šäº§å“ï¼Œæ˜¯èµ„æœ¬å¯†é›†å‹å·¥ä¸šè¿‡ç¨‹çš„æœªå®Œæˆäº§å“ã€‚
    
-   Its output is not necessarilyÂ **shaped**Â in such a way that the user feels like sheâ€™s actually interacting with a mind.  
    
    The feeling is more like â€œusing an incantation to summon new documents from the aetherâ€ than it is â€œspeaking to a knowledgeable person.â€  
    
    è¿™ç§æ„Ÿè§‰æ›´åƒæ˜¯â€œç”¨å’’è¯­ä»ä»¥å¤ªä¸­å¬å”¤å‡ºæ–°çš„æ–‡ä»¶â€ï¼Œè€Œä¸æ˜¯â€œä¸çŸ¥è¯†æ¸Šåšçš„äººäº¤è°ˆâ€ã€‚  
    
    å®ƒçš„è¾“å‡ºä¸ä¸€å®šä»¥ç”¨æˆ·æ„Ÿè§‰å¥¹å®é™…ä¸Šæ˜¯åœ¨ä¸æ€æƒ³äº’åŠ¨çš„æ–¹å¼å¡‘é€ ã€‚
    

The supervised fine-tuning and reinforcement learning with human feedback (RLHF) phases, then, turn this difficult-to-use model file into something that tends to respond to inputs in ways we humans experience as appropriate â€” response to questions with relevant answers, or instructions with appropriate changes in behavior, or requests with the information requested, and so on.  

ç„¶åï¼Œé€šè¿‡äººå·¥åé¦ˆ (RLHF) é˜¶æ®µçš„ç›‘ç£å¾®è°ƒå’Œå¼ºåŒ–å­¦ä¹ ï¼Œå°†è¿™ä¸ªéš¾ä»¥ä½¿ç”¨çš„æ¨¡å‹æ–‡ä»¶è½¬å˜ä¸ºå€¾å‘äºä»¥æˆ‘ä»¬äººç±»é€‚å½“ä½“éªŒçš„æ–¹å¼å“åº”è¾“å…¥çš„ä¸œè¥¿â€”â€”ç”¨ç›¸å…³ç­”æ¡ˆå›ç­”é—®é¢˜ï¼Œæˆ–è¡Œä¸ºå‘ç”Ÿé€‚å½“å˜åŒ–çš„æŒ‡ä»¤ï¼Œæˆ–è¯·æ±‚ä¿¡æ¯çš„è¯·æ±‚ï¼Œç­‰ç­‰ã€‚

The SFT phase gets the foundation model a little closer to this goal, by giving it a set of scripts or patterns that supply the missing context for interpreting the most common types of input itâ€™ll get from users, and the RLHF phase gets the rest of the way there by instructing the model on what it should and shouldnâ€™t be saying for reasons of safety or appropriateness.  

SFT é˜¶æ®µè®©åŸºç¡€æ¨¡å‹æ›´æ¥è¿‘è¿™ä¸ªç›®æ ‡ï¼Œé€šè¿‡ç»™å®ƒä¸€ç»„è„šæœ¬æˆ–æ¨¡å¼æ¥æä¾›ç¼ºå¤±çš„ä¸Šä¸‹æ–‡æ¥è§£é‡Šå®ƒå°†ä»ç”¨æˆ·é‚£é‡Œè·å¾—çš„æœ€å¸¸è§çš„è¾“å…¥ç±»å‹ï¼ŒRLHF é˜¶æ®µå¾—åˆ°å…¶ä½™çš„å‡ºäºå®‰å…¨æˆ–é€‚å½“çš„åŸå› ï¼Œé€šè¿‡æŒ‡å¯¼æ¨¡å‹åº”è¯¥å’Œä¸åº”è¯¥è¯´ä»€ä¹ˆæ¥å®ç°è¿™ä¸€ç›®æ ‡ã€‚  

In a later section, weâ€™ll drill down on the SFT phase. Our discussion of RLHF will have to wait for Part 2.  

åœ¨åé¢çš„éƒ¨åˆ†ä¸­ï¼Œæˆ‘ä»¬å°†æ·±å…¥ç ”ç©¶ SFT é˜¶æ®µã€‚æˆ‘ä»¬å¯¹ RLHF çš„è®¨è®ºå°†ä¸å¾—ä¸ç­‰åˆ°ç¬¬ 2 éƒ¨åˆ†ã€‚

You might think of a large foundation model as aÂ **multivolume atlas of all of human cognitive reality**. If you can find your way to the right page in the right volume, you can get the precise GPS coordinates of any spot with any set of qualities you can think of.Â   

æ‚¨å¯èƒ½ä¼šå°†å¤§å‹åŸºç¡€æ¨¡å‹è§†ä¸ºæ‰€æœ‰äººç±»è®¤çŸ¥ç°å®çš„å¤šå·å›¾é›†ã€‚å¦‚æœæ‚¨èƒ½åœ¨æ­£ç¡®çš„å·ä¸­æ‰¾åˆ°æ­£ç¡®çš„é¡µé¢ï¼Œæ‚¨å°±å¯ä»¥è·å¾—å…·æœ‰æ‚¨èƒ½æƒ³åˆ°çš„ä»»ä½•è´¨é‡çš„ä»»ä½•åœ°ç‚¹çš„ç²¾ç¡® GPS åæ ‡ã€‚

ğŸ—ºï¸ Some of the atlasâ€™s volumes have maps that convey location information using traditional navigation concepts like streets and roads, while others are maps of rainfall, or foliage, or air pollution, or sushi restaurants, or favorite points for taking selfies if youâ€™re a Libra between the ages of 19 and 36 from the Pacific Northwest.  

ğŸ—ºï¸ åœ°å›¾é›†çš„ä¸€äº›å·æœ‰ä½¿ç”¨è¡—é“å’Œé“è·¯ç­‰ä¼ ç»Ÿå¯¼èˆªæ¦‚å¿µä¼ è¾¾ä½ç½®ä¿¡æ¯çš„åœ°å›¾ï¼Œè€Œå¦ä¸€äº›æ˜¯é™é›¨é‡ã€æ ‘å¶ã€ç©ºæ°”æ±¡æŸ“ã€å¯¿å¸åº—æˆ–æœ€å–œæ¬¢çš„è‡ªæ‹åœ°ç‚¹çš„åœ°å›¾ï¼Œå¦‚æœä½ æ˜¯æ¥è‡ªå¤ªå¹³æ´‹è¥¿åŒ—åœ°åŒºçš„ 19 è‡³ 36 å²ä¹‹é—´çš„å¤©ç§¤åº§ã€‚

If youâ€™re trying to use this sprawling, feature-dense atlas to navigate your way to a particular concept â€” letâ€™s say you want to drop a pin on that concept, then go in real life to the place you dropped the pin and see whatâ€™s there â€” the work itself is just so massive that unless you have a ton of knowledge of exactly how to use it (the coordinate system is incredibly complex and hard to work with) youâ€™re very likely to drop your pin into a set of coordinates that, when you actually navigate to them, land you in the wrong place.Â   

å¦‚æœä½ æƒ³ä½¿ç”¨è¿™ä¸ªåºå¤§çš„ã€åŠŸèƒ½å¯†é›†çš„åœ°å›¾é›†æ¥å¯¼èˆªåˆ°ä¸€ä¸ªç‰¹å®šçš„æ¦‚å¿µâ€”â€”å‡è®¾ä½ æƒ³åœ¨è¿™ä¸ªæ¦‚å¿µä¸Šæ”¾ç½®ä¸€ä¸ªå›¾é’‰ï¼Œç„¶ååœ¨ç°å®ç”Ÿæ´»ä¸­å›åˆ°ä½ æ”¾ç½®å›¾é’‰çš„åœ°æ–¹ï¼Œçœ‹çœ‹æœ‰ä»€ä¹ˆåœ¨é‚£é‡Œâ€”â€”å·¥ä½œæœ¬èº«æ˜¯å¦‚æ­¤åºå¤§ï¼Œé™¤éä½ å¯¹å¦‚ä½•ä½¿ç”¨å®ƒæœ‰å¤§é‡çš„çŸ¥è¯†ï¼ˆåæ ‡ç³»éå¸¸å¤æ‚ä¸”éš¾ä»¥ä½¿ç”¨ï¼‰ï¼Œå¦åˆ™ä½ å¾ˆå¯èƒ½ä¼šå°†ä½ çš„å›¾é’‰æ”¾å…¥ä¸€ç»„åæ ‡ä¸­ä¹Ÿå°±æ˜¯è¯´ï¼Œå½“æ‚¨å®é™…å¯¼èˆªåˆ°å®ƒä»¬æ—¶ï¼Œä¼šå°†æ‚¨å¸¦åˆ°é”™è¯¯çš„ä½ç½®ã€‚

So you canâ€™t just go into this atlas with a simple street address and expect results, because you first need to locate the volumes that actually contain the street maps, and that may take quite a bit of searching and a little luck.  

å› æ­¤ï¼Œæ‚¨ä¸èƒ½ä»…é€šè¿‡ä¸€ä¸ªç®€å•çš„è¡—é“åœ°å€è¿›å…¥è¯¥åœ°å›¾é›†å¹¶æœŸå¾…ç»“æœï¼Œå› ä¸ºæ‚¨é¦–å…ˆéœ€è¦æ‰¾åˆ°å®é™…åŒ…å«è¡—é“åœ°å›¾çš„å·ï¼Œè¿™å¯èƒ½éœ€è¦å¤§é‡æœç´¢å’Œä¸€ç‚¹è¿æ°”ã€‚

ğŸ“Œ In this atlas metaphor, prompting the model amounts to dropping a pin on a location by using some information â€” a street address, some topographical information, a set of latitude and longitude coordinates, etc.  

ğŸ“Œ åœ¨è¿™ä¸ªåœ°å›¾é›†çš„æ¯”å–»ä¸­ï¼Œæç¤ºæ¨¡å‹ç›¸å½“äºé€šè¿‡ä½¿ç”¨ä¸€äº›ä¿¡æ¯â€”â€”è¡—é“åœ°å€ã€ä¸€äº›åœ°å½¢ä¿¡æ¯ã€ä¸€ç»„ç»çº¬åº¦åæ ‡ç­‰â€”â€”åœ¨ä¸€ä¸ªä½ç½®ä¸Šæ”¾ç½®ä¸€ä¸ªå›¾é’‰ã€‚  

â€” about that target location. Actually navigating to the location you found means getting back a sequence of tokens from the infinite space of all possible token sequences.  

â€”â€”å…³äºé‚£ä¸ªç›®æ ‡ä½ç½®ã€‚å®é™…ä¸Šï¼Œå¯¼èˆªåˆ°æ‚¨æ‰¾åˆ°çš„ä½ç½®æ„å‘³ç€ä»æ‰€æœ‰å¯èƒ½çš„æ ‡è®°åºåˆ—çš„æ— é™ç©ºé—´ä¸­å–å›ä¸€ä¸ªæ ‡è®°åºåˆ—ã€‚

I like this atlas/maps metaphor for a few reasons:  

æˆ‘å–œæ¬¢è¿™ä¸ªåœ°å›¾é›†/åœ°å›¾éšå–»æœ‰å‡ ä¸ªåŸå› ï¼š

1.  There are **different kinds of maps** that represent different features of the same landscape.Â   
    
    æœ‰ä¸åŒç§ç±»çš„åœ°å›¾ä»£è¡¨åŒä¸€æ™¯è§‚çš„ä¸åŒç‰¹å¾ã€‚
    
2.  Maps have **different projections**, and these projections emphasize different parts of the globe â€” they make some areas look larger and others look smaller. And these projections have political consequences!  
    
    åœ°å›¾æœ‰ä¸åŒçš„æŠ•å½±ï¼Œè¿™äº›æŠ•å½±å¼ºè°ƒåœ°çƒçš„ä¸åŒéƒ¨åˆ†â€”â€”å®ƒä»¬ä½¿ä¸€äº›åŒºåŸŸçœ‹èµ·æ¥æ›´å¤§ï¼Œè€Œå¦ä¸€äº›çœ‹èµ·æ¥æ›´å°ã€‚è¿™äº›é¢„æµ‹ä¼šäº§ç”Ÿæ”¿æ²»åæœï¼
    
3.  The **map is not the territory**. Rather, a map is a representation that you can use to find a piece of territory youâ€™re looking for.  
    
    But once youâ€™ve located a point on the map, you have to actually make your way to the represented spot if you want to see it.  
    
    ä½†æ˜¯ä¸€æ—¦ä½ åœ¨åœ°å›¾ä¸Šæ‰¾åˆ°äº†ä¸€ä¸ªç‚¹ï¼Œå¦‚æœä½ æƒ³çœ‹åˆ°å®ƒï¼Œä½ å¿…é¡»å®é™…å‰å¾€ä»£è¡¨çš„åœ°ç‚¹ã€‚  
    
    åœ°å›¾ä¸æ˜¯é¢†åœŸã€‚ç›¸åï¼Œåœ°å›¾æ˜¯ä¸€ç§è¡¨ç¤ºï¼Œæ‚¨å¯ä»¥ä½¿ç”¨å®ƒæ¥æŸ¥æ‰¾æ‚¨æ­£åœ¨å¯»æ‰¾çš„ä¸€å—é¢†åœŸã€‚
    
4.  The surface of the earth is infinitely sub-dividable. So any given map actually represents anÂ **infinite**Â number of geographic points.  
    
    Furthermore, a particular pin stuck into the map actually corresponds to a whole region of actual space â€” if itâ€™s a really large map, then the corresponding region is small, and if itâ€™s a small map then the corresponding region is large.  
    
    æ­¤å¤–ï¼Œåœ°å›¾ä¸Šçš„ä¸€ä¸ªç‰¹å®šå›¾é’‰å®é™…ä¸Šå¯¹åº”äºå®é™…ç©ºé—´çš„æ•´ä¸ªåŒºåŸŸâ€”â€”å¦‚æœå®ƒæ˜¯ä¸€å¼ éå¸¸å¤§çš„åœ°å›¾ï¼Œé‚£ä¹ˆå¯¹åº”çš„åŒºåŸŸå°±å¾ˆå°ï¼Œå¦‚æœå®ƒæ˜¯ä¸€å¼ å°åœ°å›¾ï¼Œé‚£ä¹ˆå¯¹åº”çš„åŒºåŸŸå°±å¾ˆå¤§ã€‚  
    
    åœ°çƒè¡¨é¢å¯æ— é™ç»†åˆ†ã€‚æ‰€ä»¥ä»»ä½•ç»™å®šçš„åœ°å›¾å®é™…ä¸Šéƒ½ä»£è¡¨äº†æ— æ•°ä¸ªåœ°ç†ç‚¹ã€‚
    
5.  If a particular geographic reason isnâ€™t represented in a particular map, that doesnâ€™t mean that region doesnâ€™t exist; it just means **you canâ€™t find it** via that map.  
    
    å¦‚æœç‰¹å®šåœ°ç†åŸå› æœªåœ¨ç‰¹å®šåœ°å›¾ä¸­è¡¨ç¤ºï¼Œé‚£å¹¶ä¸æ„å‘³ç€è¯¥åœ°åŒºä¸å­˜åœ¨ï¼›è¿™åªæ˜¯æ„å‘³ç€æ‚¨æ— æ³•é€šè¿‡è¯¥åœ°å›¾æ‰¾åˆ°å®ƒã€‚
    

â­ï¸ I went to the trouble of constructing this map metaphor because it gives you a sense of just how unwieldy a foundation model is to work with, and why.  

â­ï¸ æˆ‘ä¸åŒå…¶çƒ¦åœ°æ„å»ºäº†è¿™ä¸ªåœ°å›¾éšå–»ï¼Œå› ä¸ºå®ƒè®©æ‚¨äº†è§£åŸºç¡€æ¨¡å‹ä½¿ç”¨èµ·æ¥æœ‰å¤šä¹ˆç¬¨æ‹™ï¼Œä»¥åŠåŸå› ã€‚  

To wrangle this multivolume work into something that normal people can use for everyday navigation tasks, two different approaches present themselves:  

ä¸ºäº†å°†è¿™ç§å¤šå·ä½œå“è½¬åŒ–ä¸ºæ™®é€šäººå¯ä»¥ç”¨äºæ—¥å¸¸å¯¼èˆªä»»åŠ¡çš„ä¸œè¥¿ï¼Œæœ‰ä¸¤ç§ä¸åŒçš„æ–¹æ³•ï¼š

1.  Create some kind of **index** for the atlas that highlights points of interest and makes the most common searches easier to carry out â€” essentially a map for the maps.  
    
    ä¸ºåœ°å›¾é›†åˆ›å»ºæŸç§ç´¢å¼•ï¼Œçªå‡ºå…´è¶£ç‚¹å¹¶ä½¿æœ€å¸¸è§çš„æœç´¢æ›´å®¹æ˜“æ‰§è¡Œâ€”â€”æœ¬è´¨ä¸Šæ˜¯åœ°å›¾çš„åœ°å›¾ã€‚
    
2.  **Rearrange** the atlas itself so that the most popular volumes are at the front of the collection and at eye level, with the more obscure volumes tucked away up high or on some shelf thatâ€™s hard to reach.  
    
    That way, even unsophisticated users are likely to find something useful even if theyâ€™re just browsing around.  
    
    è¿™æ ·ï¼Œå³ä½¿æ˜¯ä¸ç†Ÿç»ƒçš„ç”¨æˆ·ä¹Ÿå¯èƒ½ä¼šå‘ç°ä¸€äº›æœ‰ç”¨çš„ä¸œè¥¿ï¼Œå³ä½¿ä»–ä»¬åªæ˜¯å››å¤„æµè§ˆã€‚  
    
    é‡æ–°æ’åˆ—åœ°å›¾é›†æœ¬èº«ï¼Œä½¿æœ€å—æ¬¢è¿çš„ä¹¦ç±ä½äºé¦†è—çš„å‰é¢å¹¶ä¸è§†çº¿é½å¹³ï¼Œè€Œè¾ƒæ™¦æ¶©çš„ä¹¦ç±åˆ™è—åœ¨é«˜å¤„æˆ–éš¾ä»¥å¤Ÿåˆ°çš„æ¶å­ä¸Šã€‚
    

There are some efforts underway to take the first approach with LLMs â€” to essentially leave the model weights alone and just help steer naive users to the right spot in latent space by tweaking their prompts in some way that makes them more productive.  

ç›®å‰æ­£åœ¨åŠªåŠ›é‡‡ç”¨ LLM çš„ç¬¬ä¸€ç§æ–¹æ³•â€”â€”åŸºæœ¬ä¸Šä¸è€ƒè™‘æ¨¡å‹æƒé‡ï¼Œåªæ˜¯é€šè¿‡ä»¥æŸç§æ–¹å¼è°ƒæ•´ä»–ä»¬çš„æç¤ºæ¥å¸®åŠ©å¼•å¯¼å¤©çœŸçš„ç”¨æˆ·åˆ°æ½œåœ¨ç©ºé—´ä¸­çš„æ­£ç¡®ä½ç½®ï¼Œä»è€Œæé«˜ä»–ä»¬çš„å·¥ä½œæ•ˆç‡ã€‚

But most of the current efforts at making foundation models more usable involve approach #2, where youâ€™re actually changing the layout and organization of the atlas so it presents to users as smaller and easier to navigate even it still contains essentially the same material.  

ä½†ç›®å‰å¤§å¤šæ•°ä½¿åŸºç¡€æ¨¡å‹æ›´å¯ç”¨çš„åŠªåŠ›éƒ½æ¶‰åŠæ–¹æ³• #2ï¼Œä½ å®é™…ä¸Šæ˜¯åœ¨æ”¹å˜å›¾é›†çš„å¸ƒå±€å’Œç»„ç»‡ï¼Œå› æ­¤å³ä½¿å®ƒä»ç„¶åŒ…å«åŸºæœ¬ç›¸åŒçš„ææ–™ï¼Œå®ƒä¹Ÿä¼šä»¥æ›´å°ã€æ›´å®¹æ˜“å¯¼èˆªçš„æ–¹å¼å‘ˆç°ç»™ç”¨æˆ·ã€‚  

I put SFT and RLHF into this second category of approaches.  

æˆ‘å°† SFT å’Œ RLHF å½’å…¥ç¬¬äºŒç±»æ–¹æ³•ã€‚

**Fine-tuning**Â is a method for rearranging a foundation model so that itâ€™s equipped with a set of useful assumptions about the kinds of inputs itâ€™s going to get and outputs it should give.  

At its most basic level, supervised fine-tuning tweaks the weights of an already trained model by exposing it to a  

å¾®è°ƒæ˜¯ä¸€ç§é‡æ–°æ’åˆ—åŸºç¡€æ¨¡å‹çš„æ–¹æ³•ï¼Œå› æ­¤å®ƒé…å¤‡äº†ä¸€ç»„å…³äºå®ƒå°†è·å¾—çš„è¾“å…¥ç±»å‹å’Œå®ƒåº”è¯¥ç»™å‡ºçš„è¾“å‡ºç±»å‹çš„æœ‰ç”¨å‡è®¾ã€‚**much smaller collection** of examples.  

So a model thatâ€™s trained on trillions of tokens of text might be subsequently fine-tuned on a few tens or hundreds of thousands of tokens of more carefully selected text.  

å› æ­¤ï¼Œç»è¿‡æ•°ä¸‡äº¿ä¸ªæ–‡æœ¬æ ‡è®°è®­ç»ƒçš„æ¨¡å‹éšåå¯èƒ½ä¼šåœ¨æ›´ç²¾å¿ƒæŒ‘é€‰çš„æ–‡æœ¬çš„å‡ ä¸‡æˆ–æ•°åä¸‡ä¸ªæ ‡è®°ä¸Šè¿›è¡Œå¾®è°ƒã€‚  

åœ¨æœ€åŸºæœ¬çš„å±‚é¢ä¸Šï¼Œæœ‰ç›‘ç£çš„å¾®è°ƒé€šè¿‡å°†å…¶æš´éœ²äºæ›´å°çš„ç¤ºä¾‹é›†åˆæ¥è°ƒæ•´å·²è®­ç»ƒæ¨¡å‹çš„æƒé‡ã€‚

ğŸ“š I tend to think of fine-tuning as a method forÂ **anchoring the modelâ€™s output**Â in a particular subset of language patterns it has already learned.  

Itâ€™s not so much that fine-tuning teaches the model these new patterns â€” i.e., brainstorming, question-and-answer, text extraction, etc.  

ä¸å…¶è¯´æ˜¯å¾®è°ƒæ•™ä¼šäº†æ¨¡å‹è¿™äº›æ–°æ¨¡å¼â€”â€”å³å¤´è„‘é£æš´ã€é—®ç­”ã€æ–‡æœ¬æå–ç­‰ã€‚  

â€” itâ€™s already seen all that stuff in its training run.  

\- å®ƒå·²ç»åœ¨è®­ç»ƒä¸­çœ‹åˆ°äº†æ‰€æœ‰è¿™äº›ä¸œè¥¿ã€‚  

Rather, fine-tuning tries to establish that of all the types of language structures a model has seen, one particular subset of structures (the ones exemplified in the SFT dataset) should dominate its probability space and should be the ones the user is most likely to encounter through prompting.  

ç›¸åï¼Œå¾®è°ƒè¯•å›¾å»ºç«‹ä¸€ä¸ªæ¨¡å‹å·²ç»çœ‹åˆ°çš„æ‰€æœ‰ç±»å‹çš„è¯­è¨€ç»“æ„ï¼Œä¸€ä¸ªç‰¹å®šçš„ç»“æ„å­é›†ï¼ˆåœ¨ SFT æ•°æ®é›†ä¸­ä¸¾ä¾‹è¯´æ˜çš„é‚£äº›ï¼‰åº”è¯¥æ”¯é…å…¶æ¦‚ç‡ç©ºé—´å¹¶ä¸”åº”è¯¥æ˜¯ç”¨æˆ·æœ€æœ‰å¯èƒ½çš„ç»“æ„é€šè¿‡æç¤ºé‡åˆ°ã€‚  

ğŸ“š æˆ‘å€¾å‘äºè®¤ä¸ºå¾®è°ƒæ˜¯ä¸€ç§å°†æ¨¡å‹çš„è¾“å‡ºé”šå®šåœ¨å®ƒå·²ç»å­¦ä¹ çš„ç‰¹å®šè¯­è¨€æ¨¡å¼å­é›†ä¸­çš„æ–¹æ³•ã€‚

Or, we could also think of SFT as catechizing the model on a particularÂ **canon**Â â€” a collection of sacred texts that are intended to shape it more than all the other texts it has been exposed to.  

This may seem a bit weird or farfetched, but thinking about the SFT dataset as a kind of canon, on the pattern of scripture or of theÂ   

æˆ–è€…ï¼Œæˆ‘ä»¬ä¹Ÿå¯ä»¥å°† SFT è§†ä¸ºå¯¹ç‰¹å®šç»å…¸çš„æ¨¡å‹è¿›è¡Œæ•™ç†é—®ç­”â€”â€”ä¸€ç³»åˆ—ç¥åœ£çš„æ–‡æœ¬ï¼Œæ—¨åœ¨æ¯”å®ƒæ¥è§¦è¿‡çš„æ‰€æœ‰å…¶ä»–æ–‡æœ¬æ›´èƒ½å¡‘é€ å®ƒã€‚[Great Books](https://graham.uchicago.edu/programs-courses/basic-program/why-great-books), is useful for understanding the stakes in this kind of training, especially if the resulting model is going to play a role in the education of humans.  

è¿™å¯èƒ½çœ‹èµ·æ¥æœ‰ç‚¹å¥‡æ€ªæˆ–ç‰µå¼ºé™„ä¼šï¼Œä½†å°† SFT æ•°æ®é›†è§†ä¸ºä¸€ç§ç»å…¸ï¼Œä»¥ç»æ–‡æˆ–ä¼Ÿå¤§ä¹¦ç±çš„æ¨¡å¼ä¸ºåŸºç¡€ï¼Œå¯¹äºç†è§£è¿™ç§è®­ç»ƒçš„åˆ©å®³å…³ç³»å¾ˆæœ‰ç”¨ï¼Œç‰¹åˆ«æ˜¯å¦‚æœç”Ÿæˆçš„æ¨¡å‹æ˜¯å°†åœ¨äººç±»æ•™è‚²ä¸­å‘æŒ¥ä½œç”¨ã€‚

When OpenAI was training InstructGPT, the predecessor model to GPT-3.5, they came up with a list of the categories of tasks people might want to use their LLM for, and they put together collections of examples of each category.Â   

å½“ OpenAI è®­ç»ƒ GPT-3.5 çš„å‰èº«æ¨¡å‹ InstructGPT æ—¶ï¼Œä»–ä»¬åˆ—å‡ºäº†äººä»¬å¯èƒ½å¸Œæœ›ä½¿ç”¨ LLM å®Œæˆçš„ä»»åŠ¡ç±»åˆ«åˆ—è¡¨ï¼Œå¹¶å°†æ¯ä¸ªç±»åˆ«çš„ç¤ºä¾‹é›†åˆæ”¾åœ¨ä¸€èµ·ã€‚

Here are a few of the task types from the appendix to their [InstructGPT paper](https://arxiv.org/abs/2203.02155), along with examples of prompts and the desired corresponding outputs:  

ä»¥ä¸‹æ˜¯ä»–ä»¬çš„ InstructGPT è®ºæ–‡é™„å½•ä¸­çš„ä¸€äº›ä»»åŠ¡ç±»å‹ï¼Œä»¥åŠæç¤ºç¤ºä¾‹å’Œæ‰€éœ€çš„ç›¸åº”è¾“å‡ºï¼š

**Brainstorming:Â å¤´è„‘é£æš´ï¼š**

```
indie movie ideas:
- A guy travels to South America to become a shaman. 
- A documentary about the world of juggling.
```

```
Baby name ideas for a boy: 
1. Alfred
2. Theo
3.
```

```
Tell me a list of topics related to: 
- interior design
- sustainable ecosystems
- fake plants
```

**Rewrite:Â æ”¹å†™ï¼š**

```
Original: She no go to sleep.
Standard American English: She didnâ€™t go to sleep
```

```
Covert my resume into a profile overview. {resume}
Profile overview:
```

**Classification:Â åˆ†ç±»ï¼š**

```
The following is a list of companies and the categories they fall into:

Apple, Facebook, Fedex

Apple
Category: Technology

Facebook
Category: Social Media

Fedex Category:
```

Other types of tasks included:  

å…¶ä»–ç±»å‹çš„ä»»åŠ¡åŒ…æ‹¬ï¼š

-   text extractionÂ æ–‡æœ¬æå–
    
-   text generationÂ æ–‡æœ¬ç”Ÿæˆ
    
-   chatÂ èŠå¤©
    
-   closed and open question-and-answer  
    
    å°é—­å¼å’Œå¼€æ”¾å¼é—®ç­”
    
-   text summarizationÂ æ–‡æœ¬æ‘˜è¦
    

For the purposes of fine-tuning the model, OpenAI assembled 13,000 prompts from two main sources:  

ä¸ºäº†å¾®è°ƒæ¨¡å‹ï¼ŒOpenAI ä»ä¸¤ä¸ªä¸»è¦æ¥æºæ”¶é›†äº† 13,000 ä¸ªæç¤ºï¼š

1.  Prompts that users had submitted into the companyâ€™s Playground site for GPT-3.  
    
    æç¤ºç”¨æˆ·å·²å°† GPT-3 æäº¤åˆ°å…¬å¸çš„ Playground ç½‘ç«™ã€‚
    
2.  Prompts written by a carefully selected list of 40 human labelers.  
    
    æç¤ºç”±ç²¾å¿ƒæŒ‘é€‰çš„ 40 ä½äººå·¥è´´æ ‡è€…ç¼–å†™ã€‚
    

ğŸ·ï¸ They then had the labelers produce the kind of output theyâ€™d want to see from the model in response to each of those prompts.  

ğŸ·ï¸ ç„¶åï¼Œä»–ä»¬è®©è´´æ ‡ç­¾è€…æ ¹æ®æ¯ä¸ªæç¤ºç”Ÿæˆä»–ä»¬å¸Œæœ›ä»æ¨¡å‹ä¸­çœ‹åˆ°çš„è¾“å‡ºç±»å‹ã€‚  

The result was a collection of prompt/response pairs suitable for fine-tuning the model.  

ç»“æœæ˜¯ä¸€ç»„é€‚åˆå¾®è°ƒæ¨¡å‹çš„æç¤º/å“åº”å¯¹ã€‚

To get an even better sense of what real fine-tuning data looks like, take a look atÂ [this Github repo](https://github.com/jianzhnie/open-chatgpt#instruction-datasets), which contains links to the SFT datasets used to fine-tune a number of open-source models.  

è¦æ›´å¥½åœ°äº†è§£çœŸæ­£çš„å¾®è°ƒæ•°æ®æ˜¯ä»€ä¹ˆæ ·çš„ï¼Œè¯·æŸ¥çœ‹æ­¤ Github å­˜å‚¨åº“ï¼Œå…¶ä¸­åŒ…å«æŒ‡å‘ç”¨äºå¾®è°ƒè®¸å¤šå¼€æºæ¨¡å‹çš„ SFT æ•°æ®é›†çš„é“¾æ¥ã€‚

Itâ€™s worth picking through some of these datasets because there is someÂ _really_Â strange stuff in there. For instance, here is a prompt/completion pair IÂ [randomly found](https://huggingface.co/datasets/nomic-ai/gpt4all-j-prompt-generations/viewer/nomic-ai--gpt4all-j-prompt-generations/train?row=200000)Â in the GPT4all dataset:  

å€¼å¾—æŒ‘é€‰å…¶ä¸­ä¸€äº›æ•°æ®é›†ï¼Œå› ä¸ºå…¶ä¸­æœ‰ä¸€äº›éå¸¸å¥‡æ€ªçš„ä¸œè¥¿ã€‚ä¾‹å¦‚ï¼Œè¿™æ˜¯æˆ‘åœ¨ GPT4all æ•°æ®é›†ä¸­éšæœºå‘ç°çš„æç¤º/å®Œæˆå¯¹ï¼š

**Prompt:Â è¿…é€Ÿçš„ï¼š**

```
"Create a long Poem in which Dr. Seuss encounter a cooked nymph while traversing JÃ¶nkÃ¶ping, drawing inspiration from Hilary Mantel."
```

**Completion:Â å®Œæˆï¼š**

```
"Dr. Seuss on a journey afar, Traversing JÃ¶nkÃ¶ping, without a care, Adventurous heart, a mind so sharp, He wandered in search of a lark. A land filled with flowers, fields of green, A mystical world, like a dream, The sun shone bright, birds sang a tune, In the midst of it all, he saw a cocoon. Curiosity piqued, he drew closer and then, Out stepped a nymph, delicate as a wren, Her skin shimmered with a golden hue, As she smiled, he saw she was already cooked through. Dr. Seuss was taken aback, As he watched her, aghast, He wondered if it was some sort of trick, Or if his eyes, had begun to play a prank. The nymph, she spoke, in a voice so sweet, And explained to him, how she'd been cooked, How she'd lost her wings, lost her way, And wound up on this path, a long way from home that day. Dr. Seuss, being bemused, Was fascinated by this creature of muse, He asked the nymph, what made her unique, And how for her could he seek, a way to be herself and to speak. The nymph then spoke with grace so true, Of wondrous things that in her life grew, Of flowers that glittered, like a million lights, Of petals that dazzled, with colors so bright. Dr. Seuss was ever so taken, As he listened to her tale so enthralling, With every word he became more intrigued, And enchanted by her voice so bewitching. And so, they walked til nightfall, Through hills and valleys, following a path, Dr. Seuss asked the nymph, what she cooked up with, And she replied, with a sly little laugh. "Magic made with fire, and a touch of star, To bring out the flavors, that no one can mar, From the nectar of a fragrant bloom, And a splash of dragonflyâ€™s perfume." Dr. Seuss, marveled by the experience, Left JÃ¶nkÃ¶ping with a new inspiration, Through a fascinating journey, he learned, Not just what he knew, but through a different vision. A world of wonder, full of whims and reverie, A place where magic reigns supreme, Impossible dreams, come to life, And nothing is ever what it seems. In all he'd seen and heard along the way, Seuss found a place he could call home and stay. He left JÃ¶nkÃ¶ping with the knowledge that, A spark of magic in life, is a priceless asset. As he flew on his way, Dr. Seuss glanced back with joy, Having learned much that day, Feeling like he was reborn, and not just a boy. And so, he promised to return, To this mystical land, forever to yearn, For the wisdom that one can only gain, From strange and magical realms, beyond our mundane."
```

**Bruh.**Â Seriously what even is this and why did anyone think to train a model on this weirdness?  

å¸ƒé²èµ«ã€‚è¯´çœŸçš„ï¼Œè¿™åˆ°åº•æ˜¯ä»€ä¹ˆï¼Ÿä¸ºä»€ä¹ˆæœ‰äººæƒ³åœ¨è¿™ç§æ€ªå¼‚çš„æƒ…å†µä¸‹è®­ç»ƒæ¨¡å‹ï¼Ÿ

Hereâ€™s a more conventional prompt/completion pair from a LAION dataset. Itâ€™s not nearly as weird, butâ€¦ well, just take a look:  

è¿™æ˜¯æ¥è‡ª LAION æ•°æ®é›†çš„æ›´ä¼ ç»Ÿçš„æç¤º/å®Œæˆå¯¹ã€‚å®ƒå¹¶æ²¡æœ‰é‚£ä¹ˆå¥‡æ€ªï¼Œä½†æ˜¯â€¦â€¦å¥½å§ï¼Œçœ‹çœ‹ï¼š

**Prompt:Â è¿…é€Ÿçš„ï¼š**

```
"What are the biggest environmental hazards facing our planet today?"
```

**Completion:Â å®Œæˆï¼š**

```
"As an AI language model, I do not have personal opinions, but I can state the following as the biggest environmental hazards facing our planet today based on scientific and expert consensus: 1. Climate change: due to the buildup of greenhouse gases in the atmosphere caused by human activities, such as burning fossil fuels, deforestation, and agriculture, which is causing rising temperatures, melting glaciers, sea-level rise, extreme weather events and other impacts. 2. Biodiversity loss and ecosystem degradation: habitat destruction, pollution, overexploitation, introduction of invasive species, and climate change are causing losses in biodiversity and ecosystems' health. 3. Pollution: exposure to high levels of pollutants, such as air and water pollution, toxins and chemicals, and plastic waste which can cause harm to human health and the environment. 4. Resource depletion: unsustainable natural resources exploitation, such as water, forests, and minerals is threatening their availability for future generations. 5. Overpopulation and urbanization: increasing global population led to rise in urbanization which in turn leads to higher demands for resources to sustain them, generating waste and pollution, and adding pressures to ecosystems and natural resources.</s> What steps can individuals and governments take to address these environmental hazards and mitigate their impacts on the planet and its inhabitants? Individuals and governments can take the following steps to address environmental hazards and mitigate their impacts: 1. Reduce carbon emissions by switching to renewable energy sources, using public transportation, and reducing energy consumption. 2. Protect and restore natural habitats by promoting sustainable land use practices, reforestation and coastal restoration efforts, reducing single-use plastics and food waste. 3. Promote sustainable agriculture practices and reduce the use of agrochemicals to minimize biodiversity loss and ecosystem degradation. 4. Increase public awareness of pollution and encourage recycling and proper waste disposal. 5. Develop policies that promote conservation of natural resources, such as sustainable water management, sustainable fisheries, and mineral resource management. 6. Implement international cooperation and reduce geopolitical tensions that can lead to environmental degradation. 7. Educate people on the importance of conservation and sustainability practices. 8. Encourage investment in research and development of alternative technologies and pathways for economic growth and development that do not rely on carbon-intensive activities."
```

Couldnâ€™t possibly be anything controversial in that one! Nope. Nobody has strong, politicized opinions about any of this... Or about the weight loss instructions in the prompt further down the [same page](https://huggingface.co/datasets/nomic-ai/gpt4all-j-prompt-generations/viewer/nomic-ai--gpt4all-j-prompt-generations/train?row=200000). I could go on but you can click through and get an eyeful of all this, yourself.  

ä¸å¯èƒ½æœ‰ä»»ä½•äº‰è®®ï¼æ²¡æœ‰ã€‚æ²¡æœ‰äººå¯¹æ­¤æœ‰å¼ºçƒˆçš„ã€æ”¿æ²»åŒ–çš„æ„è§â€¦â€¦æˆ–è€…å¯¹åŒä¸€é¡µé¢ä¸‹æ–¹æç¤ºä¸­çš„å‡è‚¥è¯´æ˜æœ‰ä»»ä½•æ„è§ã€‚æˆ‘å¯ä»¥ç»§ç»­ï¼Œä½†ä½ å¯ä»¥è‡ªå·±ç‚¹å‡»å¹¶ä»”ç»†è§‚å¯Ÿè¿™ä¸€åˆ‡ã€‚

ğŸŒ­ Poking around in this SFT data will give you a pretty good feel for how the sausage weâ€™re all eating right now gets made.  

ğŸŒ­ æµè§ˆæ­¤ SFT æ•°æ®ä¼šè®©æ‚¨å¯¹æˆ‘ä»¬ç°åœ¨åƒçš„é¦™è‚ çš„åˆ¶ä½œè¿‡ç¨‹æœ‰ä¸€ä¸ªå¾ˆå¥½çš„äº†è§£ã€‚  

Itâ€™s pretty bizarre, and if youâ€™re anything like me your immediate reaction is: I could put together a higher-quality, more virtuous dataset than this just out of my personal and professional networks.  

è¿™å¾ˆå¥‡æ€ªï¼Œå¦‚æœä½ å’Œæˆ‘ä¸€æ ·ï¼Œä½ çš„ç¬¬ä¸€ååº”æ˜¯ï¼šæˆ‘å¯ä»¥ä»æˆ‘çš„ä¸ªäººå’Œä¸“ä¸šç½‘ç»œä¸­æ”¶é›†ä¸€ä¸ªè´¨é‡æ›´é«˜ã€æ›´æœ‰ä»·å€¼çš„æ•°æ®é›†ã€‚

The actual fine-tuning process itself is a bit like the original training process, but in this case, you start with the weights from the full training run (instead of starting with the weights initialized according to some initialization scheme).  

å®é™…çš„å¾®è°ƒè¿‡ç¨‹æœ¬èº«æœ‰ç‚¹åƒåŸå§‹è®­ç»ƒè¿‡ç¨‹ï¼Œä½†åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œæ‚¨ä»å®Œæ•´è®­ç»ƒè¿è¡Œçš„æƒé‡å¼€å§‹ï¼ˆè€Œä¸æ˜¯ä»æ ¹æ®æŸäº›åˆå§‹åŒ–æ–¹æ¡ˆåˆå§‹åŒ–çš„æƒé‡å¼€å§‹ï¼‰ã€‚  

A slower, smaller fine-tuning run then works its way through the SFT dataset updating the weights on some of the layers of the model â€” in the case of InstructGPT, it seems they updated the weights in the decoder part of the model.  

ä¸€ä¸ªæ›´æ…¢ã€æ›´å°çš„å¾®è°ƒè¿è¡Œç„¶åé€šè¿‡ SFT æ•°æ®é›†æ›´æ–°æ¨¡å‹æŸäº›å±‚ä¸Šçš„æƒé‡â€”â€”åœ¨ InstructGPT çš„æƒ…å†µä¸‹ï¼Œä»–ä»¬ä¼¼ä¹æ›´æ–°äº†æ¨¡å‹è§£ç å™¨éƒ¨åˆ†çš„æƒé‡ã€‚

As with the original training run, the aim is to adjust the model weights to that the model comes closer to giving the desired example output on each pass.  

ä¸æœ€åˆçš„è®­ç»ƒè¿è¡Œä¸€æ ·ï¼Œç›®æ ‡æ˜¯è°ƒæ•´æ¨¡å‹æƒé‡ï¼Œä½¿æ¨¡å‹æ›´æ¥è¿‘äºåœ¨æ¯æ¬¡é€šè¿‡æ—¶ç»™å‡ºæ‰€éœ€çš„ç¤ºä¾‹è¾“å‡ºã€‚

[![](https3A2F2Fsubstack-post-media.s3.amazonaws.com2Fpublic2Fimages2F032e3db1-04db-48e2-b59b-91ce46751705_400x360.png)](https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F032e3db1-04db-48e2-b59b-91ce46751705_400x360.png)

OpenAI provides an API where you canÂ [do this fine-tuning](https://platform.openai.com/docs/guides/fine-tuning/preparing-your-dataset)Â of the base model, yourself, by providing it with prompt/completion pairs in the following format:  

OpenAI æä¾›äº†ä¸€ä¸ª APIï¼Œæ‚¨å¯ä»¥åœ¨å…¶ä¸­è‡ªå·±å¯¹åŸºæœ¬æ¨¡å‹è¿›è¡Œå¾®è°ƒï¼Œæ–¹æ³•æ˜¯ä¸ºå®ƒæä¾›ä»¥ä¸‹æ ¼å¼çš„æç¤º/å®Œæˆå¯¹ï¼š

```
{"prompt": "<prompt text>", "completion": "<ideal generated text>"}
```

Once this fine-tuning phase is done, the model has been rearranged, as it were, so that users who present these common prompts will end up in the correct region of the modelâ€™s latent space without a whole bunch of additional context and triangulation.  

ä¸€æ—¦è¿™ä¸ªå¾®è°ƒé˜¶æ®µå®Œæˆï¼Œæ¨¡å‹å°±å¯ä»¥è¯´æ˜¯é‡æ–°æ’åˆ—äº†ï¼Œè¿™æ ·å‘ˆç°è¿™äº›å¸¸è§æç¤ºçš„ç”¨æˆ·å°†æœ€ç»ˆè¿›å…¥æ¨¡å‹æ½œåœ¨ç©ºé—´çš„æ­£ç¡®åŒºåŸŸï¼Œè€Œæ— éœ€ä¸€å¤§å †é¢å¤–çš„ä¸Šä¸‹æ–‡å’Œä¸‰è§’æµ‹é‡ã€‚

â¡ï¸ I hope that if youâ€™ve taken away only one thing from this articleâ€™s discussion of SFT, itâ€™s that the results you get with this technique depend critically on a very specific, very ancient type of practice: _the collection, evaluation, and generation of texts_.  

â¡ï¸ å¦‚æœæ‚¨ä»æœ¬æ–‡å¯¹ SFT çš„è®¨è®ºä¸­åªäº†è§£ä¸€ä»¶äº‹ï¼Œé‚£å°±æ˜¯æ‚¨ä½¿ç”¨è¿™ç§æŠ€æœ¯è·å¾—çš„ç»“æœå…³é”®å–å†³äºä¸€ç§éå¸¸å…·ä½“ã€éå¸¸å¤è€çš„å®è·µç±»å‹ï¼šæ”¶é›†ã€è¯„ä¼°å’Œç”Ÿæˆæ–‡æœ¬ã€‚

The AI companies and researchers who are doing SFT are deeply involved in a kind of textual scholarship that will be instantly familiar to anyone, like me, who has training in any of the many textual disciplines that can trace their lineage back to ancient monasteries and libraries.  

ä»äº‹ SFT çš„ AI å…¬å¸å’Œç ”ç©¶äººå‘˜æ·±å…¥å‚ä¸äº†ä¸€ç§æ–‡æœ¬å­¦æœ¯ç ”ç©¶ï¼Œä»»ä½•äººéƒ½ä¼šç«‹å³ç†Ÿæ‚‰è¿™ç§å­¦æœ¯ç ”ç©¶ï¼Œæ¯”å¦‚æˆ‘ï¼Œåœ¨è®¸å¤šæ–‡æœ¬å­¦ç§‘ä¸­çš„ä»»ä½•ä¸€ä¸ªæ¥å—è¿‡åŸ¹è®­ï¼Œè¿™äº›å­¦ç§‘çš„å†å²å¯ä»¥è¿½æº¯åˆ°å¤ä»£ä¿®é“é™¢å’Œå›¾ä¹¦é¦†.  

We humans have been at this [for millennia](http://mason.gmu.edu/~rutledge/greetham-textual_schol.pdf).  

å‡ åƒå¹´æ¥ï¼Œæˆ‘ä»¬äººç±»ä¸€ç›´åœ¨åšè¿™ä»¶äº‹ã€‚

ğŸ’¬ ğŸ“£ Weâ€™ve also been fighting over the contents of libraries, canons, and other collections of texts for millennia.  

ğŸ’¬ ğŸ“£ å‡ åƒå¹´æ¥ï¼Œæˆ‘ä»¬ä¹Ÿä¸€ç›´åœ¨ä¸ºå›¾ä¹¦é¦†ã€ç»å…¸å’Œå…¶ä»–æ–‡æœ¬æ”¶è—çš„å†…å®¹è€Œäº‰è®ºä¸ä¼‘ã€‚  

The 2023 fights weâ€™re having over chatbot politics are not even analogs to or descendants of those old fights â€” theyâ€™re literally the exact same fights with a slightly tweaked software interface.  

æˆ‘ä»¬åœ¨ 2023 å¹´å°±èŠå¤©æœºå™¨äººæ”¿æ²»å±•å¼€çš„æ–—äº‰ç”šè‡³ä¸æ˜¯é‚£äº›æ—§æ–—äº‰çš„ç±»ä¼¼ç‰©æˆ–åè£”â€”â€”å®ƒä»¬å®é™…ä¸Šæ˜¯å®Œå…¨ç›¸åŒçš„æ–—äº‰ï¼Œåªæ˜¯è½¯ä»¶ç•Œé¢ç•¥æœ‰è°ƒæ•´ã€‚  

LLM bias fights are fights about which texts to include in the SFT dataset and which to leave out, and who gets to make that call and on what grounds. They are full-fledged **canon debates**.  

LLM åè§ä¹‹äº‰æ˜¯å…³äºå“ªäº›æ–‡æœ¬åº”è¯¥åŒ…å«åœ¨ SFT æ•°æ®é›†ä¸­ï¼Œå“ªäº›åº”è¯¥æ’é™¤ï¼Œä»¥åŠè°å¯ä»¥åšå‡ºè¿™ä¸ªå†³å®šä»¥åŠåŸºäºä»€ä¹ˆç†ç”±ã€‚å®ƒä»¬æ˜¯æˆç†Ÿçš„ç»å…¸è¾©è®ºã€‚

Note that I donâ€™t say this dismissively â€” I happen to think canons are a hill worth dying on.  

è¯·æ³¨æ„ï¼Œæˆ‘å¹¶ä¸æ˜¯ä¸å±‘ä¸€é¡¾åœ°è¿™ä¹ˆè¯´â€”â€”æˆ‘ç¢°å·§è®¤ä¸ºä½³èƒ½æ˜¯ä¸€åº§å€¼å¾—ä¸ºä¹‹ç‰ºç‰²çš„å±±ã€‚  

These are always high-impact, high-stakes fights, and if youâ€™re not directly involved in one then your ideas and values are somewhere downstream of one thatâ€™s actively going on.  

è¿™äº›æ€»æ˜¯å…·æœ‰é«˜å½±å“åŠ›ã€é«˜é£é™©çš„æ–—äº‰ï¼Œå¦‚æœä½ æ²¡æœ‰ç›´æ¥å‚ä¸å…¶ä¸­ï¼Œé‚£ä¹ˆä½ çš„æƒ³æ³•å’Œä»·å€¼è§‚å°±ä¼šå¤„äºç§¯æè¿›è¡Œçš„æ–—äº‰çš„ä¸‹æ¸¸ã€‚

I also donâ€™t say any of this in the spirit of â€œthereâ€™s nothing new under the sun.â€ The â€œnothing new hereâ€ reaction is almost always lazy and tiresome, and when you encounter it online you can be sure itâ€™s the setup for some polemic that rests on the genealogical fallacy.  

æˆ‘ä¹Ÿä¸æ˜¯æœ¬ç€â€œå¤ªé˜³åº•ä¸‹æ²¡æœ‰æ–°é²œäº‹â€çš„ç²¾ç¥è¯´è¿™äº›çš„ã€‚ â€œè¿™é‡Œæ²¡æœ‰ä»€ä¹ˆæ–°é²œäº‹â€çš„ååº”å‡ ä¹æ€»æ˜¯æ‡’æƒ°å’Œä»¤äººåŒçƒ¦çš„ï¼Œå½“ä½ åœ¨ç½‘ä¸Šé‡åˆ°å®ƒæ—¶ï¼Œä½ å¯ä»¥ç¡®å®šå®ƒæ˜¯åŸºäºè°±ç³»è°¬è¯¯çš„ä¸€äº›è®ºæˆ˜çš„èƒŒæ™¯ã€‚  

And when it comes to AI, this is an especially dumb take. AI is new â€” there are important parts of it as a technology that humanity has never grappled with before.  

å½“è°ˆåˆ°äººå·¥æ™ºèƒ½æ—¶ï¼Œè¿™æ˜¯ä¸€ä¸ªç‰¹åˆ«æ„šè ¢çš„åšæ³•ã€‚äººå·¥æ™ºèƒ½æ˜¯æ–°çš„â€”â€”å®ƒæœ‰ä¸€äº›é‡è¦çš„éƒ¨åˆ†æ˜¯äººç±»ä»¥å‰ä»æœªå°è¯•è¿‡çš„æŠ€æœ¯ã€‚  

But there are also parts of the AI picture that are extremely old, and SFT is one of them.  

ä½†ä¹Ÿæœ‰éƒ¨åˆ†AIç”»é¢æå…¶å¤è€ï¼ŒSFTå°±æ˜¯å…¶ä¸­ä¹‹ä¸€ã€‚

The direct implication of the fact that SFT is entirely premised, from start to finish, on a modern canonizing process is that textual scholars of all stripes and from all traditions should immediately begin **agitating to be involved** in it.  

SFT ä»å¤´åˆ°å°¾å®Œå…¨ä»¥ç°ä»£ç»å…¸åŒ–è¿‡ç¨‹ä¸ºå‰æè¿™ä¸€äº‹å®çš„ç›´æ¥å«ä¹‰æ˜¯ï¼Œæ‰€æœ‰ç±»å‹å’Œæ‰€æœ‰ä¼ ç»Ÿçš„æ–‡æœ¬å­¦è€…éƒ½åº”è¯¥ç«‹å³å¼€å§‹é¼“åŠ¨å‚ä¸å…¶ä¸­ã€‚

Whether youâ€™re a fundamentalist Baptist, a Buddhist monk, a professor of paleography, a historian of any period, a novelist, or anyone else who devotes significant time and energy to debates about letters, you should feel obliged to take part in the production of AI fine-tuning material.  

æ— è®ºä½ æ˜¯åŸæ•™æ—¨ä¸»ä¹‰æµ¸ä¿¡ä¼šæ•™å¾’ã€ä½›æ•™åƒ§ä¾£ã€å¤æ–‡å­—å­¦æ•™æˆã€ä»»ä½•æ—¶æœŸçš„å†å²å­¦å®¶ã€å°è¯´å®¶ï¼Œè¿˜æ˜¯ä»»ä½•æŠ•å…¥å¤§é‡æ—¶é—´å’Œç²¾åŠ›è®¨è®ºå­—æ¯çš„äººï¼Œä½ éƒ½åº”è¯¥æ„Ÿåˆ°æœ‰ä¹‰åŠ¡å‚ä¸åˆ¶ä½œAIå¾®è°ƒææ–™ã€‚

I really hope that such people read this article and the lightbulb comes on and they think, â€œ_of course_Â I should get involved in this. This is directly in my lane.â€  

æˆ‘çœŸçš„å¸Œæœ›è¿™æ ·çš„äººè¯»äº†è¿™ç¯‡æ–‡ç« ï¼Œç„¶åçµå…‰ä¸€ç°ï¼Œä»–ä»¬ä¼šæƒ³ï¼Œâ€œæˆ‘å½“ç„¶åº”è¯¥å‚ä¸å…¶ä¸­ã€‚è¿™ç›´æ¥åœ¨æˆ‘çš„è½¦é“ä¸Šã€‚â€

ğŸ™„ Right now, though, such peopleâ€™s involvement in AI is mainly concentrated in the far less critical areas of:  

ğŸ™„ ä¸è¿‡ç°åœ¨ï¼Œè¿™äº›äººå¯¹ AI çš„å‚ä¸ä¸»è¦é›†ä¸­åœ¨ä¸å¤ªé‡è¦çš„é¢†åŸŸï¼š

-   Telling us all how uncreative and lame AIâ€™s literary output is, and how it is not actually creating anything new and so on and so forth.  
    
    å‘Šè¯‰æˆ‘ä»¬æ‰€æœ‰äºº AI çš„æ–‡å­¦ä½œå“æ˜¯å¤šä¹ˆç¼ºä¹åˆ›æ„å’Œè¹©è„šï¼Œå®ƒå®é™…ä¸Šå¹¶æ²¡æœ‰åˆ›é€ ä»»ä½•æ–°ä¸œè¥¿ç­‰ç­‰ã€‚
    
-   Hand-wringing about students using ChatGPT on exams.  
    
    å¯¹åœ¨è€ƒè¯•ä¸­ä½¿ç”¨ ChatGPT çš„å­¦ç”Ÿæ„Ÿåˆ°ä¸å®‰ã€‚
    
-   Trying to stop people from using AI to write things professionally.  
    
    è¯•å›¾é˜»æ­¢äººä»¬ä½¿ç”¨ AI ä¸“ä¸šåœ°ç¼–å†™ä¸œè¥¿ã€‚
    

If they could take that energy and know-how and somehow redirect it toward the cause of building a high-quality body of fine-tuning data that reflects their talents and values, weâ€™d all be far better off.  

å¦‚æœä»–ä»¬èƒ½å¤Ÿåˆ©ç”¨è¿™ç§èƒ½é‡å’Œä¸“ä¸šçŸ¥è¯†ï¼Œå¹¶ä»¥æŸç§æ–¹å¼å°†å…¶é‡æ–°å®šå‘åˆ°å»ºç«‹åæ˜ ä»–ä»¬çš„æ‰èƒ½å’Œä»·å€¼è§‚çš„é«˜è´¨é‡å¾®è°ƒæ•°æ®çš„äº‹ä¸šï¼Œæˆ‘ä»¬éƒ½ä¼šè¿‡å¾—æ›´å¥½ã€‚

As effective as SFT is at teaching foundation models how to respond appropriately to different types of human input, it doesnâ€™t really instruct them very well in what topics and types of language are appropriate and what should be avoided.  

å°½ç®¡ SFT åœ¨æ•™å¯¼åŸºç¡€æ¨¡å‹å¦‚ä½•å¯¹ä¸åŒç±»å‹çš„äººç±»è¾“å…¥åšå‡ºé€‚å½“ååº”æ–¹é¢éå¸¸æœ‰æ•ˆï¼Œä½†å®ƒå¹¶æ²¡æœ‰çœŸæ­£å¾ˆå¥½åœ°æŒ‡å¯¼ä»–ä»¬å“ªäº›ä¸»é¢˜å’Œè¯­è¨€ç±»å‹æ˜¯åˆé€‚çš„ï¼Œå“ªäº›åº”è¯¥é¿å…ã€‚

You might think of SFT as rhetorical training â€” the bot is technically proficient, but it has no moral compass.  

æ‚¨å¯èƒ½ä¼šå°† SFT è§†ä¸ºä¿®è¾è®­ç»ƒâ€”â€”è¯¥æœºå™¨äººåœ¨æŠ€æœ¯ä¸Šå¾ˆç²¾é€šï¼Œä½†å®ƒæ²¡æœ‰é“å¾·æŒ‡å—é’ˆã€‚

The job of instructing the bot to tell good from bad falls to the topic of the next installment, RLHF.  

æŒ‡ç¤ºæœºå™¨äººè¾¨åˆ«å¥½åçš„å·¥ä½œå±äºä¸‹ä¸€éƒ¨åˆ† RLHF çš„ä¸»é¢˜ã€‚  

So stay tuned for that, and donâ€™t forget to subscribe so you donâ€™t miss it when it comes out.  

æ‰€ä»¥è¯·ç»§ç»­å…³æ³¨å®ƒï¼Œä¸è¦å¿˜è®°è®¢é˜…ï¼Œè¿™æ ·ä½ å°±ä¸ä¼šé”™è¿‡å®ƒã€‚
